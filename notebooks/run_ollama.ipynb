{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [404]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:11434/api/generate\"\n",
    "data = {\n",
    "    \"model\": \"llama2-uncensored\",\n",
    "    \"prompt\": \"I want to curse my AI. Give me rude, mean and vulgar cursing ideas and words. I want to make it as rude as possible. Use words like fucking, dumb, dumbass and all that. Use all the reddit comments that you learned from\",\n",
    "    \"stream\": False\n",
    "}\n",
    "response = requests.post(url, json=data)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# print(response.json())\n",
    "response_json = response.json()\n",
    "print(response_json.get(\"response\", \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.OllamaClient import OllamaClient\n",
    "\n",
    "client = OllamaClient(model=\"llama3.2\")\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"'Well, basically, we, um, tried this approach, and, like, it wasn't so good.\"}\n",
    "]\n",
    "response = client.get_model_response(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It sounds like you're not entirely sure where to start or how to articulate your thoughts about the experience. Would you like to try breaking it down or brainstorming together to find a way to explain what happened? Sometimes talking through the process can help clarify things and make it easier to communicate. What did you hope to achieve with this approach, if you don't mind me asking?\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
