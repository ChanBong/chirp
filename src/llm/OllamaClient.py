from typing import Dict, Optional, List, Any
import json
import os
from datetime import datetime
import requests
import re
from termcolor import colored


class OllamaClient:
    """Class to handle Ollama API calls."""
    def __init__(self, model: str = "llama3.2:latest", base_url: str = "http://localhost:11434"):
        self.model = model
        self.base_url = base_url.rstrip('/')
        self._initialized = False
        self.verbose = True

    def is_initialized(self) -> bool:
        return self._initialized
    
    def initialize(self, options: Dict[str, Any]):
        self._initialized = True

    def save_conversation(self, messages: List[Dict], filename: Optional[str] = None):
        """Save the conversation to a JSON file.
        
        Args:
            messages (list): List of message dictionaries
            filename (str, optional): The filename to save to
        """
        if not filename:
            filename = datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + "_conversation.json"
        with open(filename, 'w') as f:
            json.dump(messages, f, indent=4)

    def stream_completion(self, messages, model, **kwargs):
        """
        Stream text completions from the Ollama API.

        Args:
            messages (list): List of messages used as context or prompt.
            model (str): Model identifier for text generation.
            **kwargs: Additional keyword arguments for the API request.

        Yields:
            str: Text generated by the Ollama API in response to the messages.
        """
        url = f"{self.base_url}/api/chat"
        data = {
            "model": model,
            "messages": messages,
            "stream": True,
            "keep_alive": 600,
            **kwargs

        }
        json_data = json.dumps(data)
        # headers = {'Authorization': f'Bearer {self.api_key}'} if self.api_key else {}
        try:
            with requests.post(url, data=json_data, stream=True) as response:
                if response.status_code == 200:
                    for chunk in response.iter_content(chunk_size=None):
                        if chunk:
                            # Parse the JSON response and extract the content
                            response_data = json.loads(chunk)
                            yield response_data['message']['content']
                else:
                    if self.verbose:
                        print(f"Request failed with status code {response.status_code}")
                    raise RuntimeError(f"Request failed with status code {response.status_code}")
        except Exception as e:
            if self.verbose:
                import traceback
                traceback.print_exc()
            else:
                print(f"An error occurred streaming completion from Ollama API: {e}")
            raise RuntimeError(f"An error occurred streaming completion from Ollama API: {e}")

    def cleanup(self):
        self.model = None
        self._initialized = False
